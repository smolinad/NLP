{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as funct\n",
    "g = torch.Generator().manual_seed(14442)\n",
    "\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "import random\n",
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"names.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = sorted(list(set(\".\".join(words))))\n",
    "char_to_idx = {c: i for i, c in enumerate(alphabet)}\n",
    "idx_to_char = {i: c for i, c in enumerate(alphabet)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 3\n",
    "emb_length = 60\n",
    "batch_size = 100\n",
    "num_neurons = 1000\n",
    "\n",
    "def build_dataset(words:list):\n",
    "    xs, ys = [], []\n",
    "    for w in words:\n",
    "        context = [0]*context_size\n",
    "        for ch in w + \".\":\n",
    "            idx = char_to_idx[ch]\n",
    "            xs.append(context)\n",
    "            ys.append(idx)\n",
    "            context = context[1:] + [idx]\n",
    "    xs, ys = torch.tensor(xs), torch.tensor(ys)\n",
    "\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(words)\n",
    "\n",
    "n1 = int(0.8*len(words)); n2 = int(0.9*len(words))\n",
    "x_train, y_train = build_dataset(words[:n1])\n",
    "x_val, y_val = build_dataset(words[n1:n2])\n",
    "x_test, y_test = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setting\n",
    "- set $b_2 = 0$ and scale $W_2$ by a small constant to drag the initial loss to $0$.\n",
    "\n",
    "### Kaiming init\n",
    "- Initialization of weights to prevent saturation when applying the non-linearity.\n",
    "\n",
    "### Batchnorm\n",
    "- Normalizes each batch in training to be approximately gaussian up to scaling and translation.\n",
    "- Removes the effect of bias when centering the data.\n",
    "- Highly inefficient in deep networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup table \n",
    "C = torch.randn((len(alphabet), emb_length), generator=g)\n",
    "\n",
    "# Hidden layer\n",
    "# Kaiming init for tanh (to avoid saturation of tanh).\n",
    "W1 = torch.randn((context_size * emb_length, num_neurons), generator=g) * (5/3) / (context_size * emb_length)**0.5\n",
    "#b1 = torch.randn(num_neurons, generator=g) # Has no effect in batch normalization.\n",
    "\n",
    "# Output layer\n",
    "W2 = torch.randn((num_neurons, len(alphabet)), generator=g) * 0.1 #To reduce initial setting loss\n",
    "b2 = torch.randn(27, generator=g) * 0\n",
    "\n",
    "\n",
    "bnscale = torch.ones((1, num_neurons))\n",
    "bnshift = torch.zeros((1, num_neurons))\n",
    "\n",
    "params = [C, W1, W2, b2, bnscale, bnshift]\n",
    "\n",
    "for p in params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 \t|\t Loss: 4.94409\n",
      "Iter 2500 \t|\t Loss: 2.05342\n",
      "Iter 5000 \t|\t Loss: 2.18867\n",
      "Iter 7500 \t|\t Loss: 2.24115\n",
      "Iter 10000 \t|\t Loss: 2.34288\n",
      "Iter 12500 \t|\t Loss: 2.30169\n",
      "Iter 15000 \t|\t Loss: 1.91409\n",
      "Iter 17500 \t|\t Loss: 2.16541\n",
      "Iter 20000 \t|\t Loss: 1.96124\n",
      "Iter 22500 \t|\t Loss: 2.29328\n",
      "Iter 25000 \t|\t Loss: 2.10862\n",
      "Iter 27500 \t|\t Loss: 1.91253\n",
      "Iter 30000 \t|\t Loss: 2.26748\n",
      "Iter 32500 \t|\t Loss: 1.79838\n",
      "Iter 35000 \t|\t Loss: 2.04707\n",
      "Iter 37500 \t|\t Loss: 2.16278\n",
      "Iter 40000 \t|\t Loss: 1.95799\n",
      "Iter 42500 \t|\t Loss: 2.14786\n",
      "Iter 45000 \t|\t Loss: 1.81286\n",
      "Iter 47500 \t|\t Loss: 1.87609\n",
      "Iter 50000 \t|\t Loss: 1.95449\n",
      "Iter 52500 \t|\t Loss: 1.99352\n",
      "Iter 55000 \t|\t Loss: 1.99787\n",
      "Iter 57500 \t|\t Loss: 1.92874\n",
      "Iter 60000 \t|\t Loss: 2.24800\n",
      "Iter 62500 \t|\t Loss: 2.05478\n",
      "Iter 65000 \t|\t Loss: 1.94512\n",
      "Iter 67500 \t|\t Loss: 1.89472\n",
      "Iter 70000 \t|\t Loss: 2.01362\n",
      "Iter 72500 \t|\t Loss: 1.94915\n",
      "Iter 75000 \t|\t Loss: 1.87865\n",
      "Iter 77500 \t|\t Loss: 2.03388\n",
      "Iter 80000 \t|\t Loss: 2.26627\n",
      "Iter 82500 \t|\t Loss: 2.08557\n",
      "Iter 85000 \t|\t Loss: 2.10816\n",
      "Iter 87500 \t|\t Loss: 1.95854\n",
      "Iter 90000 \t|\t Loss: 1.98254\n",
      "Iter 92500 \t|\t Loss: 2.13150\n",
      "Iter 95000 \t|\t Loss: 1.97219\n",
      "Iter 97500 \t|\t Loss: 2.08115\n"
     ]
    }
   ],
   "source": [
    "bn_mean = torch.zeros((1, num_neurons))\n",
    "bn_std = torch.ones((1, num_neurons))\n",
    "\n",
    "for i in range(100000):\n",
    "    batch = torch.randint(0, x_train.shape[0], (batch_size, ))\n",
    "    embedding = C[x_train[batch]]\n",
    "    hpreact = embedding.view(-1, context_size * emb_length) @ W1 #+ b1) #Bias not needed as normalization removes its effect.\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # BatchNorm the preactivation (converting in to approx. a Gaussian distr.)\n",
    "    bn_mean_i = hpreact.mean(0, keepdim=True)\n",
    "    bn_std_i =  hpreact.std(0, keepdim=True)\n",
    "    h1 = bnscale * (hpreact - bn_mean_i) / (bn_std_i + 0.01) + bnshift\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bn_mean = 0.999*bn_mean + 0.001*bn_mean_i\n",
    "        bn_std = 0.999*bn_std + 0.001*bn_std_i\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Non-linearity\n",
    "    h1 = torch.tanh(h1) \n",
    "    logits = h1 @ W2 + b2\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Loss\n",
    "    loss = funct.cross_entropy(logits, y_train[batch]) #Equivalent to mean of neg log-likelihood\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    if i%2500==0:\n",
    "        print(f\"Iter {i} \\t|\\t Loss: {loss:.5f}\")\n",
    "\n",
    "    for p in params:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    lr = 0.1 if i < 30000 else 0.001\n",
    "\n",
    "    for p in params:\n",
    "        p.data += -lr * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def eval_loss(split:str):\n",
    "    x, y = {\"train\": (x_train, y_train), \"val\": (x_val, y_val), \"test\": (x_test, y_test)}[split]\n",
    "    embedding_val = C[x]\n",
    "    hpreact = embedding_val.view(-1, context_size * emb_length) @ W1 #+ b1\n",
    "    h1 = bnscale * (hpreact - bn_mean) / (bn_std + 0.01) + bnshift\n",
    "    h1 = torch.tanh(h1) \n",
    "    logits = h1 @ W2 + b2\n",
    "    loss = funct.cross_entropy(logits, y)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.9783), tensor(2.0638))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loss(\"train\"), eval_loss(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "C_emb = TSNE(n_components=2, perplexity=5).fit_transform(C.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d9b7b30d2c74473e907ae706dbcc67a9.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d9b7b30d2c74473e907ae706dbcc67a9.vega-embed details,\n",
       "  #altair-viz-d9b7b30d2c74473e907ae706dbcc67a9.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d9b7b30d2c74473e907ae706dbcc67a9\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d9b7b30d2c74473e907ae706dbcc67a9\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d9b7b30d2c74473e907ae706dbcc67a9\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"tooltip\": [{\"field\": \"char\", \"type\": \"nominal\"}], \"x\": {\"field\": \"x1\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"x2\", \"type\": \"quantitative\"}}, \"name\": \"view_1\"}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"middle\", \"dx\": 7}, \"encoding\": {\"text\": {\"field\": \"char\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"char\", \"type\": \"nominal\"}], \"x\": {\"field\": \"x1\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"x2\", \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-0893c699e37d3d977fe7714b7a28a51c\"}, \"height\": 500, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\", \"views\": [\"view_1\"]}], \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-0893c699e37d3d977fe7714b7a28a51c\": [{\"x1\": 5.522579193115234, \"x2\": 3.735321521759033, \"char\": \".\"}, {\"x1\": 3.038851499557495, \"x2\": -4.946781158447266, \"char\": \"a\"}, {\"x1\": -32.21894073486328, \"x2\": 43.884891510009766, \"char\": \"b\"}, {\"x1\": 8.480735778808594, \"x2\": 17.022315979003906, \"char\": \"c\"}, {\"x1\": -0.12193477898836136, \"x2\": -25.686511993408203, \"char\": \"d\"}, {\"x1\": -6.458547592163086, \"x2\": 9.867953300476074, \"char\": \"e\"}, {\"x1\": -24.85845375061035, \"x2\": -36.097930908203125, \"char\": \"f\"}, {\"x1\": -48.4417724609375, \"x2\": -20.028841018676758, \"char\": \"g\"}, {\"x1\": 60.07701873779297, \"x2\": 1.0534729957580566, \"char\": \"h\"}, {\"x1\": 16.993083953857422, \"x2\": 33.33149337768555, \"char\": \"i\"}, {\"x1\": -9.68542194366455, \"x2\": 28.94874382019043, \"char\": \"j\"}, {\"x1\": -13.864843368530273, \"x2\": -9.163532257080078, \"char\": \"k\"}, {\"x1\": 5.663817882537842, \"x2\": -50.418033599853516, \"char\": \"l\"}, {\"x1\": 34.87721633911133, \"x2\": -0.09231925010681152, \"char\": \"m\"}, {\"x1\": -18.269330978393555, \"x2\": -26.970788955688477, \"char\": \"n\"}, {\"x1\": -46.090850830078125, \"x2\": 4.4939045906066895, \"char\": \"o\"}, {\"x1\": -11.299683570861816, \"x2\": 42.41931915283203, \"char\": \"p\"}, {\"x1\": -24.1822452545166, \"x2\": 22.63829231262207, \"char\": \"q\"}, {\"x1\": 19.070293426513672, \"x2\": -17.569753646850586, \"char\": \"r\"}, {\"x1\": 27.719812393188477, \"x2\": -32.56636047363281, \"char\": \"s\"}, {\"x1\": 6.211153984069824, \"x2\": 62.33104705810547, \"char\": \"t\"}, {\"x1\": 46.1444206237793, \"x2\": 29.247074127197266, \"char\": \"u\"}, {\"x1\": 17.233810424804688, \"x2\": 0.6870854496955872, \"char\": \"v\"}, {\"x1\": 25.632762908935547, \"x2\": 14.56871509552002, \"char\": \"w\"}, {\"x1\": 45.47124099731445, \"x2\": -23.608009338378906, \"char\": \"x\"}, {\"x1\": 25.46722984313965, \"x2\": 44.186256408691406, \"char\": \"y\"}, {\"x1\": -29.470083236694336, \"x2\": 1.9410476684570312, \"char\": \"z\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr = pd.DataFrame({\"x1\": C_emb[:, 0], \"x2\": C_emb[:, 1], \"char\": alphabet})\n",
    "\n",
    "scatter = alt.Chart(repr).mark_circle(size=60).encode(\n",
    "    x='x1',\n",
    "    y='x2',\n",
    "    tooltip=['char']\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=500\n",
    ").interactive()\n",
    "\n",
    "chars = scatter.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=7\n",
    ").encode(\n",
    "    text='char'\n",
    ")\n",
    "\n",
    "scatter + chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sai\n",
      "rem\n",
      "zaleigh\n",
      "daciony\n",
      "acean\n",
      "bryson\n",
      "temillouis\n",
      "sha\n",
      "kylah\n",
      "nyelfo\n",
      "sry\n",
      "jamena\n",
      "mae\n",
      "doriel\n",
      "eleia\n",
      "jevelia\n",
      "dio\n",
      "abrinley\n",
      "drea\n",
      "shreecilphoella\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    idx = 0 \n",
    "    res = \"\"\n",
    "    cont = [0] * context_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor(cont)]\n",
    "        hpreact = emb.view(-1, context_size * emb_length) @ W1\n",
    "        h = bnscale * (hpreact - bn_mean) / (bn_std + 0.01) + bnshift\n",
    "        h = torch.tanh(h) #+ b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = funct.softmax(logits, dim=1)\n",
    "        idx = torch.multinomial(probs, 1, replacement=True, generator=g).item()\n",
    "        if idx==0:\n",
    "            break\n",
    "        \n",
    "        res += idx_to_char[idx]\n",
    "        cont = cont[1: ] + [idx]\n",
    "\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
